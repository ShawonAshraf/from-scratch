{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3d06b2-2dac-46b4-862e-a9fbfec6e966",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "HF: [batterydata/pos_tagging](https://huggingface.co/datasets/batterydata/pos_tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734bcaf9-a721-47ba-bf12-d1f46d55389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9cc65034a646a795ab2a0a33c06add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4fcdd2e43e46b7997d1568f91e1c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a75a8b28c25405c8afe21833a3a168b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/601k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1e5e5eb6674a45a0658fabf72917b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97320c12d9b3449aab7c521c802a63a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"batterydata/pos_tagging\"\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8e37d-3c1d-4607-acd5-3acaad0f6bb1",
   "metadata": {},
   "source": [
    "### Integer mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6261d-ba27-421f-b5af-ed94a89db087",
   "metadata": {},
   "source": [
    "Taking a pre-transformer era NLP approach with a fixed vocab from the training dataset with OOV and PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207d6743-6ab8-44ea-84c9-b5e97c8171f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict containing word -> idx mapping\n",
    "def create_word_indices(dataset):\n",
    "    unique_words = set()\n",
    "    word_to_idx = dict()\n",
    "    # add an out of vocab token\n",
    "    oov_token = \"<OOV>\"\n",
    "    pad_token = \"<PAD>\"\n",
    "    word_to_idx[oov_token] = 0\n",
    "    word_to_idx[pad_token] = 1\n",
    "    \n",
    "    # find unique words\n",
    "    for data in dataset:\n",
    "        words = data[\"words\"]\n",
    "        for w in words:\n",
    "            unique_words.add(w)\n",
    "            \n",
    "    # add index to them\n",
    "    for idx, uw in enumerate(list(unique_words)):\n",
    "        word_to_idx[uw] = idx + 2 # since oov is at 0 and pad at 1\n",
    "        \n",
    "    \n",
    "    return word_to_idx\n",
    "\n",
    "\n",
    "# ===============\n",
    "word_to_idx = create_word_indices(dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a3e94-e3d4-48ca-84b3-53beda179fe4",
   "metadata": {},
   "source": [
    "word_to_idx maps each word in the vocabulary to an integer label. Ultimately, we need integer ids for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8d8aaa-a1ea-4bfb-88a4-41de723f6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_to_idx(dataset):\n",
    "    unique_labels = set()\n",
    "    label_to_idx = dict()\n",
    "    # add an out of vocab token\n",
    "    oov_token = \"<OOV>\"\n",
    "    pad_token = \"<PAD>\"\n",
    "    label_to_idx[oov_token] = 0\n",
    "    label_to_idx[pad_token] = 1\n",
    "    \n",
    "    # find the labels\n",
    "    for data in dataset:\n",
    "        labels = data[\"labels\"]\n",
    "        for l in labels:\n",
    "            unique_labels.add(l)\n",
    "            \n",
    "    # index\n",
    "    for idx, label in enumerate(list(unique_labels)):\n",
    "        label_to_idx[label] = idx + 2\n",
    "        \n",
    "    return label_to_idx\n",
    "    \n",
    "label_to_idx = create_label_to_idx(dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a808800-8de5-4de4-881a-5bab952de5d3",
   "metadata": {},
   "source": [
    "parts of speech tags are categorical data. We can one hot encode them or just use integer labels. Pytorch loss functions can work with both. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a643a45-90ad-4d77-8ca6-da7d074c3f5f",
   "metadata": {},
   "source": [
    "\n",
    "### Encoding\n",
    "\n",
    "Given a single data instance, which is a sentence and corresponding pos tags, this function will encode the words and the tags using the word / tag to integer mappings we created earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9eca9b9-9fe5-4bab-baaf-922f7ca73edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single instance\n",
    "def encode_data_instance(data, word_to_idx, label_to_idx):\n",
    "    words = [\n",
    "        word_to_idx.get(word, word_to_idx[\"<OOV>\"]) for word in data[\"words\"]\n",
    "    ]\n",
    "    \n",
    "    labels = [\n",
    "        label_to_idx[label] for label in data[\"labels\"]\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"words\": words,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1aa36-2a3c-465b-a0f2-f6807bf4ff7a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Splits\n",
    "\n",
    "The problem with this dataset is that it doesn't come with a validation set. You should always have a validation set to check your training.\n",
    "\n",
    "Also setting a random seed helps reproducing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9840de40-1545-4229-9002-45a59012f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_validation_splits(dataset_split,\n",
    "                                 validation_split=0.2,\n",
    "                                 seed=42):\n",
    "    # make a copy of the data\n",
    "    dataset_split = dataset_split.shuffle(seed=seed)\n",
    "    # using the train test split method to create validation set\n",
    "    dataset_split = dataset_split.train_test_split(test_size=validation_split,\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=seed)\n",
    "    return dataset_split[\"train\"], dataset_split[\"test\"]\n",
    "\n",
    "\n",
    "\n",
    "def prepare_splits(dataset,\n",
    "                   validation_size=0.2,\n",
    "                   seed=42):\n",
    "    # train and test split\n",
    "    train_split = dataset[\"train\"]\n",
    "    test_split = dataset[\"test\"]\n",
    "\n",
    "    train_split, validation_split = make_train_validation_splits(train_split, validation_size, seed)\n",
    "    return train_split, validation_split, test_split\n",
    "\n",
    "\n",
    "\n",
    "train_split, validation_split, test_split = prepare_splits(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b435c-7a60-49fc-a45f-fb007c194493",
   "metadata": {},
   "source": [
    "### Torch Dataset\n",
    "\n",
    "Padding index is 1 (as set in the vocab before). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70540d79-efed-41ed-bf1c-bdd0705b5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# set seeds\n",
    "np.random.seed(2023)\n",
    "torch.manual_seed(2023)\n",
    "\n",
    "\n",
    "\n",
    "class TagDataset(Dataset):\n",
    "    def __init__(self, dataset_split,\n",
    "                 pad_token_idx,\n",
    "                 word_to_idx,\n",
    "                 label_to_idx) -> None:\n",
    "        self.dataset = dataset_split\n",
    "        self.pad_token_idx = pad_token_idx\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.label_to_idx = label_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    # use word_to_idx and label_to_idx to convert\n",
    "    # the string sequences to int sequences\n",
    "    def __encode(self, data_instance):\n",
    "        words = data_instance[\"words\"]\n",
    "        labels = data_instance[\"labels\"]\n",
    "\n",
    "        # convert to int sequences\n",
    "        words = [self.word_to_idx.get(w, 0) for w in words]\n",
    "        labels = [self.label_to_idx.get(l) for l in labels]\n",
    "\n",
    "        words = torch.tensor(words)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        return words, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        words, labels = self.__encode(data)\n",
    "\n",
    "        return words, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5c9f2f-5b1e-4a14-ba31-b35841cae013",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    \"pad_token_idx\": 1,\n",
    "    \"word_to_idx\": word_to_idx,\n",
    "    \"label_to_idx\": label_to_idx\n",
    "}\n",
    "\n",
    "train_set = TagDataset(train_split, **dataset_config)\n",
    "val_set = TagDataset(validation_split, **dataset_config)\n",
    "test_set = TagDataset(test_split, **dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313ba49-7ba1-4203-8ac7-4efcd044c46c",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "To stack all the variable length sequences the dataloader will expect them to be padded. One quick way to do this is to use pad_sequence from pytorch. This way, you don't have to mention a fixed padding size. Also, it's memory efficient since you're not always passing large sparse sequences per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9277be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    # pad token is 1\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=1)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=1)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e15f58-5f02-4327-9803-4eb0e88c3dfa",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148b2a95-6290-48cf-910b-c7c63629be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "   train_set, batch_size=128, shuffle=True, collate_fn=pad_collate)\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=128, shuffle=False, collate_fn=pad_collate)\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=128, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f414fb5d-a6ed-4c1c-97d0-563e60cacddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 67])\n",
      "torch.Size([128, 67])\n"
     ]
    }
   ],
   "source": [
    "# =========== test a dataloader ==========\n",
    "for batch in train_loader:\n",
    "    w, l, ws, ls = batch\n",
    "    print(w.size())\n",
    "    print(l.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab36ff7-7901-41b4-bbf1-283aaff6f7f3",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model here consists of a single LSTM layer with embedding. The embedding is trained from the corpus, can also be replaced with word2vec embeddings from gensim.\n",
    "\n",
    "LR default 1e-3 for Adam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc555f5-09df-4eed-8d9d-1e007cc8135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ef9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for newer nvidia gpus\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b854ff1-ae2a-4327-b265-acea7ce8810d",
   "metadata": {},
   "source": [
    "Pytorch lightning to make things easier. xD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32953c4f-1c81-4faa-aeab-f67ac10574bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "from tqdm.auto import trange, tqdm\n",
    "from einops import rearrange\n",
    "import lightning.pytorch as L\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMTagger(L.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dimension, projection_dims, n_labels, pad_idx) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # hparams\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.projection_dims = projection_dims\n",
    "        self.n_labels = n_labels\n",
    "        self.pad_idx = pad_idx\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # modules\n",
    "        self.embedding = nn.Embedding(self.vocab_size, \n",
    "                                      self.embedding_dimension, \n",
    "                                      padding_idx=self.pad_idx)\n",
    "        self.lstm = nn.LSTM(self.embedding_dimension, self.projection_dims, batch_first=True)        \n",
    "        self.fc = nn.Linear(self.projection_dims, self.n_labels)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "                \n",
    "    def forward(self, x, xlen):\n",
    "        out = self.embedding(x) \n",
    "        # out = self.dropout(out)\n",
    "        \n",
    "        # this reshaping changed things. :3 Well hell pytorch\n",
    "        # out = rearrange(out, \"batch L embed -> batch embed L\")\n",
    "        \n",
    "        # pack padded sequence\n",
    "        out = pack_padded_sequence(out, xlen, batch_first=True, enforce_sorted=False)        \n",
    "        out, _ = self.lstm(out)\n",
    "        \n",
    "        # back to padded \n",
    "        out, _ = pad_packed_sequence(out, batch_first=True, padding_value=1)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = F.leaky_relu(out)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def compute_loss(self, batch):\n",
    "        words, labels, word_len, _ = batch\n",
    "        \n",
    "        logits = self(words, word_len)\n",
    "        # reshape logits\n",
    "        logits = rearrange(logits, \"batch seq log -> batch log seq\")\n",
    "        \n",
    "        loss = F.cross_entropy(logits, labels, ignore_index=self.pad_idx)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return optim.AdamW(self.parameters())\n",
    "    \n",
    "    def training_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        loss = self.compute_loss(batch)\n",
    "        \n",
    "        self.log(\"Loss/Train\", loss, prog_bar=True, \n",
    "                 batch_size=batch[0].size(0))\n",
    "        \n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"log\": {\n",
    "                \"Loss/Train\": loss\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        loss = self.compute_loss(batch)\n",
    "\n",
    "        self.log(\"Loss/Validation\", loss, prog_bar=True,\n",
    "                 batch_size=batch[0].size(0))\n",
    "\n",
    "        return {\n",
    "            \"val_loss\": loss,\n",
    "            \"log\": {\n",
    "                \"Loss/Validation\": loss\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a25867f0-1a2c-4cee-90ce-b72cb6bb6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(len(word_to_idx), 300, 300, len(label_to_idx), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cfa2986-e7fb-49a6-98e0-d0d50dd8b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9149)\n"
     ]
    }
   ],
   "source": [
    "# sample forward pass\n",
    "\n",
    "with torch.no_grad():\n",
    "     for batch in train_loader:\n",
    "         loss = model.compute_loss(batch)    \n",
    "         print(loss)\n",
    "         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4cab7b-d98f-4242-b5a8-0fa5b2956f97",
   "metadata": {},
   "source": [
    "### Logging and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12882b01-1aef-46d6-a91c-d9aeb781ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensorboard logger\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"tb_logs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c89df76d-b7e7-4f6c-bb9d-2358d17f3bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# create the lightning trainer\n",
    "\n",
    "trainer = L.Trainer(logger=tb_logger,\n",
    "                    max_epochs=10,\n",
    "                    accelerator=\"gpu\",\n",
    "                    devices=1,\n",
    "                    precision=\"bf16-mixed\",\n",
    "                    log_every_n_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddb822c9-a101-4011-9075-957d5b3412db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: tb_logs/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 7.5 M \n",
      "1 | lstm      | LSTM      | 722 K \n",
      "2 | fc        | Linear    | 15.1 K\n",
      "3 | dropout   | Dropout   | 0     \n",
      "----------------------------------------\n",
      "8.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.2 M     Total params\n",
      "32.769    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a30617c98b64224ae5983dc217be876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/from-scratch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/opt/conda/envs/from-scratch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be2b8c782dc4fc783bc9d1960a4e027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db56c3252c334e0b9bc9edd0c1e1e3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e769589e8642c5b0f7e5e1c24f79f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3ee80606df43ecb4c8edae1529cc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8aa62476e34d7b881ec46d2e17911d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fb55ec5a9c49cf9fe2e3bb29b9e58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facecd6814944d14a438a95e41dcf10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b993137accfd4e8f87fcd662a14a8c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bff88500b54c6b80ab0e6c2872edc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea596358310423194ae59bde0f4e089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5aa19bb64a482eb41065d2c274e1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebcbd36-e74c-45b1-a923-615790526d80",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Categorical accuracy ignores the padded indexes and checks for matches in the non padded ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac6f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy, torch eq is weird\n",
    "def categorical_accuracy(preds, actual):\n",
    "    non_pad = np.nonzero(actual != 1)\n",
    "    matches = np.equal(preds[non_pad], actual[non_pad]).sum()\n",
    "    return matches / actual[non_pad].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b9cda5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629a0ce992c84fddb6bb22c85738c754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9849, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86218df94dc4922b51577ed8f818139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9307, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a709e0810a45b59c68a8e7475bd937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9271, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(dataloader):\n",
    "    scores = list()\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        words, labels, wlen, _ = batch\n",
    "        words = words\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(words, wlen)\n",
    "            \n",
    "        probas = logits.log_softmax(dim=-1)\n",
    "        \n",
    "        preds = probas.argmax(dim=-1)\n",
    "        \n",
    "        acc = categorical_accuracy(preds.numpy(), labels.numpy())\n",
    "        scores.append(acc)\n",
    "        \n",
    "        \n",
    "    print(torch.tensor(scores).mean(dim=-1))\n",
    "    \n",
    "\n",
    "# ================\n",
    "evaluate(train_loader)\n",
    "evaluate(val_loader)\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ae536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
