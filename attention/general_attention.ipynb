{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more generalised form of attention\n",
    "\n",
    "There are some issues with the method described in bahdanau. First, it's hard-tied to a RNN based encoder decoder model. What if you don't want to use recurrent networks. Second, it needs the outputs from the encoder and decoder to form the information space (encoder state) and the search space (decoder output) to get probable output candidates; but you may not always want to model seq2seq using attention. \n",
    "\n",
    "\n",
    "So there is a more generalised version of attention, which uses the terms key, query and values to describe the attention process. \n",
    "\n",
    "To find parallels with the bahdanau method, \n",
    "\n",
    "query : what we want to know or search (decoder output)\n",
    "\n",
    "key: what information we have (and can be used for searching) , (the encoder state)\n",
    "\n",
    "value: the probability of the search result being related to the query (in the bahdanau paper, values are the same as the keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the implementation details become this:\n",
    "\n",
    "Say you have an input sequence $X$,\n",
    "\n",
    "Then you need a query representation (with a query weight)\n",
    "A key rep (same, another weight) and so on for value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size for the input\n",
    "seq_len = 50\n",
    "src = torch.arange(seq_len)\n",
    "tgt = torch.arange(seq_len) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def attention(src: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    # modules\n",
    "    src_embed = nn.Embedding(100, 10)\n",
    "    tgt_embed = nn.Embedding(100, 10)\n",
    "    \n",
    "    Q = nn.Linear(10, 10)\n",
    "    K = nn.Linear(10, 10)\n",
    "    V = nn.Linear(10, 10)\n",
    "    \n",
    "    x = src_embed(src)\n",
    "    y = tgt_embed(target)\n",
    "    \n",
    "    \n",
    "    q = Q(x)\n",
    "    k = K(y)\n",
    "    # src -> target attetntion\n",
    "    # optimising the target to be aligned with the src\n",
    "    # so values come from the src\n",
    "    v = V(x)\n",
    "    \n",
    "    # now that we have q, k, v\n",
    "    \n",
    "    attention_scores = q @ k.T\n",
    "    alpha = attention_scores.softmax(dim=-1)\n",
    "    # attention\n",
    "    a = alpha @ v\n",
    "    return a\n",
    "\n",
    "\n",
    "a = attention(src, tgt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.6128e-02, -2.9233e-01, -2.4212e-01, -2.5898e-01,  3.5666e-02,\n",
       "         -1.2268e-01,  2.5762e-01,  3.5595e-01, -9.5216e-02, -9.7683e-02],\n",
       "        [ 4.3134e-02, -3.7733e-01, -2.3537e-01, -2.8420e-01,  2.0973e-02,\n",
       "         -1.8788e-01,  3.3490e-01,  2.7411e-01,  7.4452e-02, -7.2363e-02],\n",
       "        [-1.2856e-02, -4.9443e-01, -1.6425e-01, -1.7546e-01, -9.8770e-02,\n",
       "          4.4919e-02,  4.5979e-01,  1.1665e-01, -9.5980e-02,  8.1025e-02],\n",
       "        [-3.4816e-02, -3.5247e-01, -2.0780e-01, -3.1957e-01,  7.1137e-02,\n",
       "         -3.3858e-02,  3.6715e-01,  2.7959e-01,  1.2284e-01, -1.4793e-01],\n",
       "        [ 2.1492e-02, -3.5198e-01, -9.7461e-02, -2.8343e-01,  9.7485e-02,\n",
       "         -6.8736e-02,  3.1947e-01,  2.3882e-01, -2.1193e-02, -1.0721e-01],\n",
       "        [ 1.4464e-01, -4.0921e-01, -2.7013e-01, -1.9694e-01,  1.6508e-01,\n",
       "         -1.5613e-01,  2.3145e-01, -2.9909e-02, -1.8270e-01, -1.9135e-01],\n",
       "        [-1.5929e-02, -4.3593e-01, -2.1074e-01, -2.3540e-01, -7.0843e-02,\n",
       "         -3.9005e-02,  4.2824e-01,  2.6784e-01, -1.0703e-02,  4.4068e-02],\n",
       "        [ 9.0480e-02, -4.3281e-01, -1.6998e-01, -2.2561e-01,  7.5227e-02,\n",
       "         -1.2353e-01,  3.0518e-01,  1.2292e-01, -1.5733e-01, -1.4030e-02],\n",
       "        [-1.9272e-02, -3.6883e-01, -1.6316e-01, -2.7280e-01,  2.1524e-02,\n",
       "          2.8824e-02,  4.2111e-01,  2.4564e-01, -5.9988e-02, -4.6386e-02],\n",
       "        [-2.9785e-02, -4.0802e-01, -2.3852e-01, -2.2385e-01, -1.2279e-01,\n",
       "          4.7019e-02,  5.0809e-01,  2.7323e-01, -1.6205e-01,  1.0832e-01],\n",
       "        [ 6.4715e-02, -4.6644e-01, -8.7417e-02, -2.2501e-01,  1.2960e-02,\n",
       "         -6.7654e-02,  3.5061e-01,  1.1345e-01, -1.4217e-01,  8.8409e-02],\n",
       "        [-5.8121e-02, -3.6582e-01, -2.0468e-01, -2.9602e-01, -6.8292e-02,\n",
       "          6.9920e-02,  4.0037e-01,  3.1463e-01, -9.2406e-03,  5.9214e-02],\n",
       "        [ 5.1168e-02, -4.7724e-01, -2.2196e-01, -1.8243e-01,  2.0213e-02,\n",
       "         -9.0249e-02,  3.6831e-01,  2.0189e-01, -2.2850e-01,  1.3211e-02],\n",
       "        [ 2.7814e-02, -4.7639e-01, -1.8376e-01, -2.0307e-01,  1.1635e-01,\n",
       "         -2.7179e-01,  2.6886e-01,  2.5368e-01,  9.7594e-03, -1.8777e-01],\n",
       "        [-1.2769e-02, -4.5650e-01, -2.0521e-01, -2.4106e-01, -1.1146e-01,\n",
       "          3.4408e-03,  4.8589e-01,  2.3300e-01, -1.1726e-01,  1.4206e-01],\n",
       "        [ 6.3424e-02, -3.6799e-01, -7.5562e-02, -2.3629e-01,  3.0150e-02,\n",
       "         -3.3599e-02,  2.9490e-01,  1.6068e-01, -2.5154e-01,  1.4794e-01],\n",
       "        [-3.2540e-02, -3.5479e-01, -1.7099e-01, -2.8382e-01, -3.4112e-02,\n",
       "          5.1676e-02,  4.0802e-01,  2.9407e-01, -7.2232e-02,  5.1989e-02],\n",
       "        [ 8.3027e-02, -3.6295e-01, -2.2299e-01, -2.4433e-01,  1.2854e-01,\n",
       "         -1.0309e-01,  4.0109e-01,  2.2461e-01, -1.1552e-01, -1.4210e-01],\n",
       "        [-6.0495e-03, -5.0108e-01, -1.4715e-01, -1.4689e-01, -5.3278e-02,\n",
       "          9.6655e-02,  4.7483e-01,  2.1377e-02, -1.2108e-01, -4.1725e-04],\n",
       "        [-2.0736e-02, -4.5600e-01, -1.7185e-01, -2.2248e-01,  1.7408e-01,\n",
       "         -3.2095e-02,  3.8386e-01,  1.2007e-01, -2.1432e-02, -2.8318e-01],\n",
       "        [ 4.5123e-02, -3.9206e-01, -9.8831e-02, -2.6424e-01,  1.4919e-01,\n",
       "         -1.4012e-01,  2.9699e-01,  2.1328e-01, -4.4031e-02, -1.7881e-01],\n",
       "        [ 2.1867e-02, -4.9237e-01, -1.3370e-01, -2.3681e-01,  4.7956e-02,\n",
       "         -1.1972e-01,  3.0936e-01,  1.6590e-01, -2.1001e-02, -5.6939e-02],\n",
       "        [ 4.3420e-02, -3.3386e-01, -1.5658e-01, -2.4088e-01,  6.6211e-02,\n",
       "         -1.3328e-02,  3.3683e-01,  1.6520e-01, -1.7510e-01, -3.4944e-02],\n",
       "        [-5.5584e-03, -4.2904e-01, -2.5678e-01, -2.2608e-01, -9.5099e-02,\n",
       "         -1.2867e-01,  3.7150e-01,  3.3801e-01,  4.0560e-02,  3.7935e-02],\n",
       "        [ 2.3906e-02, -4.6832e-01, -1.9671e-01, -1.5246e-01,  3.1399e-01,\n",
       "         -3.3808e-02,  4.6797e-01, -1.1209e-02, -1.1830e-01, -5.4484e-01],\n",
       "        [-3.9220e-02, -4.9348e-01, -1.6965e-01, -1.8154e-01,  4.7424e-03,\n",
       "          1.0519e-02,  4.3369e-01,  1.6997e-01, -1.0456e-01, -5.6591e-02],\n",
       "        [ 2.9966e-02, -4.5815e-01, -1.2876e-01, -1.8467e-01,  5.0196e-03,\n",
       "         -1.8514e-02,  3.8555e-01,  1.4466e-01, -1.7283e-01,  2.7203e-02],\n",
       "        [-7.2094e-03, -4.0670e-01, -1.8000e-01, -2.5504e-01, -5.5056e-02,\n",
       "          5.3983e-03,  4.4457e-01,  2.2410e-01, -7.1040e-02,  5.4503e-02],\n",
       "        [-7.4967e-02, -4.3012e-01, -2.3825e-01, -2.2002e-01, -1.5586e-01,\n",
       "          8.7959e-02,  4.6495e-01,  3.2976e-01, -1.0482e-01,  1.3561e-01],\n",
       "        [ 1.5065e-02, -2.9839e-01, -1.4848e-01, -2.7253e-01,  3.8668e-02,\n",
       "          7.5806e-02,  4.5480e-01,  2.0937e-01, -2.0658e-01, -1.2014e-02],\n",
       "        [ 3.9265e-02, -5.0587e-01, -6.8609e-02, -2.2083e-01, -3.0615e-02,\n",
       "         -6.4733e-02,  3.4138e-01,  1.3971e-01, -1.0216e-01,  1.1209e-01],\n",
       "        [ 1.1847e-02, -4.0911e-01, -2.7386e-01, -2.8224e-01, -6.0726e-02,\n",
       "         -2.0147e-01,  3.2823e-01,  3.1883e-01,  1.8172e-01, -8.9119e-03],\n",
       "        [ 9.5457e-02, -3.9621e-01, -1.2804e-01, -1.9640e-01,  1.0190e-01,\n",
       "         -1.2656e-01,  3.2017e-01,  1.4286e-01, -2.2980e-01, -6.7077e-02],\n",
       "        [-6.3662e-02, -5.0405e-01, -2.1633e-01, -1.6171e-01, -1.9202e-01,\n",
       "          3.1691e-02,  5.0818e-01,  2.8329e-01, -1.0970e-01,  1.7992e-01],\n",
       "        [-4.3806e-03, -4.9000e-01, -1.6852e-01, -1.3268e-01,  1.5143e-01,\n",
       "          1.3050e-01,  5.2058e-01, -7.3268e-02, -1.3765e-01, -3.2436e-01],\n",
       "        [ 3.7093e-02, -3.6171e-01, -9.9973e-02, -2.3737e-01,  6.7172e-02,\n",
       "         -4.6039e-02,  3.7258e-01,  2.0896e-01, -1.5359e-01, -3.7459e-02],\n",
       "        [ 1.4461e-01, -3.8230e-01, -4.0977e-02, -1.9061e-01,  1.4312e-01,\n",
       "         -2.3473e-01,  1.4179e-01,  1.1904e-01, -2.0883e-01, -3.5869e-03],\n",
       "        [ 2.6244e-02, -3.7837e-01, -1.2918e-01, -2.5871e-01,  9.8194e-03,\n",
       "         -4.4299e-02,  3.4160e-01,  2.4946e-01, -9.7138e-02,  5.6973e-02],\n",
       "        [ 1.0998e-01, -4.4495e-01, -1.9854e-01, -1.8599e-01,  8.1296e-02,\n",
       "         -8.0400e-02,  3.6510e-01,  3.1807e-02, -2.5234e-01, -4.2175e-02],\n",
       "        [-2.4426e-02, -3.0076e-01, -2.3089e-01, -3.0133e-01, -2.2876e-02,\n",
       "         -1.0616e-02,  3.3925e-01,  3.8085e-01,  2.2023e-02, -3.1610e-02],\n",
       "        [ 9.7698e-03, -4.5232e-01, -2.1096e-01, -2.3453e-01, -6.3239e-02,\n",
       "         -8.9072e-02,  4.3031e-01,  2.5349e-01, -4.9621e-02,  6.3163e-02],\n",
       "        [-7.8511e-02, -3.9407e-01, -2.4393e-01, -1.9823e-01, -1.9069e-01,\n",
       "          1.0302e-01,  5.1833e-01,  3.6413e-01, -1.7535e-01,  1.4287e-01],\n",
       "        [-6.7031e-02, -4.1284e-01, -1.9190e-01, -1.9216e-01, -1.1664e-01,\n",
       "          1.3918e-01,  4.9284e-01,  2.4053e-01, -1.5716e-01,  9.4258e-02],\n",
       "        [ 5.9259e-03, -3.2252e-01, -2.1164e-02, -2.4079e-01, -7.6106e-02,\n",
       "          3.9516e-03,  3.5657e-01,  2.9137e-01, -1.9541e-01,  2.7496e-01],\n",
       "        [-1.3516e-03, -4.0823e-01, -1.2190e-01, -2.5034e-01,  8.5991e-03,\n",
       "         -9.1479e-03,  3.7808e-01,  2.0989e-01, -4.7510e-02, -1.3487e-04],\n",
       "        [-4.2907e-02, -4.6493e-01, -2.6310e-01, -2.1055e-01, -1.3649e-01,\n",
       "         -3.1119e-02,  4.2940e-01,  3.5055e-01, -1.0006e-01,  1.1629e-01],\n",
       "        [-4.0736e-02, -4.4390e-01, -2.2154e-01, -2.2246e-01, -1.2025e-01,\n",
       "         -1.7129e-02,  4.3765e-01,  3.2413e-01, -3.8628e-02,  1.0383e-01],\n",
       "        [-4.8029e-04, -3.9565e-01, -1.6297e-01, -2.4834e-01, -9.9551e-03,\n",
       "         -2.4918e-02,  3.9519e-01,  2.4357e-01, -4.6306e-02,  3.1305e-03],\n",
       "        [-4.0524e-02, -2.8204e-01, -2.2861e-01, -3.0066e-01, -1.9143e-02,\n",
       "          8.5369e-02,  4.0839e-01,  3.9060e-01, -1.5830e-01,  5.2055e-03],\n",
       "        [ 2.8418e-02, -3.9482e-01, -2.1690e-01, -2.8616e-01, -1.4653e-02,\n",
       "         -9.6647e-02,  3.7886e-01,  2.5597e-01,  7.7003e-03,  3.5511e-03]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
