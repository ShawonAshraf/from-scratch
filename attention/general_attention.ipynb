{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more generalised form of attention\n",
    "\n",
    "There are some issues with the method described in bahdanau. First, it's hard-tied to a RNN based encoder decoder model. What if you don't want to use recurrent networks. Second, it needs the outputs from the encoder and decoder to form the information space (encoder state) and the search space (decoder output) to get probable output candidates; but you may not always want to model seq2seq using attention. \n",
    "\n",
    "\n",
    "So there is a more generalised version of attention, which uses the terms key, query and values to describe the attention process. \n",
    "\n",
    "To find parallels with the bahdanau method, \n",
    "\n",
    "query : what we want to know or search (decoder output)\n",
    "\n",
    "key: what information we have (and can be used for searching) , (the encoder state)\n",
    "\n",
    "value: the probability of the search result being related to the query (in the bahdanau paper, values are the same as the keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the implementation details become this:\n",
    "\n",
    "Say you have an input sequence $X$,\n",
    "\n",
    "Then you need a query representation (with a query weight)\n",
    "A key rep (same, another weight) and so on for value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size for the input\n",
    "seq_len = 50\n",
    "x = torch.arange(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay this here becomes more of a self-attention\n",
    "# so when both query and key come from the input sequence,\n",
    "# attention is comparing the input to itself\n",
    "# becomes self attetnion\n",
    "\n",
    "@torch.no_grad()\n",
    "def attention(sequence: torch.Tensor) -> torch.Tensor:\n",
    "    # modules\n",
    "    embed = nn.Embedding(100, 10)\n",
    "    Q = nn.Linear(10, 10)\n",
    "    K = nn.Linear(10, 10)\n",
    "    V = nn.Linear(10, 10)\n",
    "    \n",
    "    x = embed(sequence)\n",
    "    q = Q(x)\n",
    "    k = K(x)\n",
    "    v = V(x)\n",
    "    \n",
    "    # now that we have q, k, v\n",
    "    \n",
    "    attention_scores = q @ k.T\n",
    "    alpha = attention_scores.softmax(dim=-1)\n",
    "    # attention\n",
    "    a = attention_scores @ q\n",
    "    return a\n",
    "\n",
    "\n",
    "a = attention(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6716e+01,  1.1041e+01, -1.1626e+01,  1.7849e+01, -1.7858e+01,\n",
       "          5.4379e+00, -1.6980e+01,  2.4383e+01,  5.2313e+00, -1.3040e+01],\n",
       "        [-4.5440e+00,  2.7986e+01,  3.2808e+00, -1.9986e+00, -2.3787e+01,\n",
       "          1.1641e+00,  1.6745e+01,  1.0561e+01,  6.5427e+00, -1.0154e+01],\n",
       "        [ 1.2910e+01, -2.3780e+01,  6.0605e+00, -1.2543e+01,  1.2747e+01,\n",
       "         -2.4295e+00,  3.5230e+00, -1.7888e+01, -2.0508e+00,  1.1265e+01],\n",
       "        [ 7.4843e+00, -6.9338e+00, -5.6274e+00,  3.3967e+00,  6.3810e+00,\n",
       "          6.5698e+00, -1.1233e+00, -4.4610e+00, -3.9812e+00,  4.2825e+00],\n",
       "        [-3.4243e+00,  2.6711e+00, -2.1215e-01, -2.2021e+00,  4.1969e-01,\n",
       "          1.1941e+00, -4.6860e+00,  3.1345e+00,  7.6051e+00, -1.4732e+01],\n",
       "        [ 2.4758e+00,  2.3400e+00,  3.3501e+00,  1.3557e+01,  9.1841e+00,\n",
       "          6.3338e+00, -1.7144e+01,  1.1330e+01, -1.3698e+00, -2.7343e+01],\n",
       "        [ 1.3977e+01, -1.7247e+01,  6.7863e+00, -9.2467e+00,  5.6533e+00,\n",
       "          8.0504e-01,  1.3043e+01, -1.7175e+01, -5.4793e+00,  2.8885e+01],\n",
       "        [ 1.0037e+01,  9.8407e+00,  5.8834e+00,  4.1990e+00, -5.1440e+00,\n",
       "          4.5787e+00,  9.1061e+00,  2.1283e+00, -8.6654e+00, -1.0493e+01],\n",
       "        [-1.0417e+00,  2.1252e+01,  2.2499e-01,  9.1580e+00, -3.1469e+00,\n",
       "          5.9293e+00, -2.5883e+00,  1.0944e+01, -1.6876e+00, -2.9242e+01],\n",
       "        [ 3.6673e+00, -6.2897e+00,  2.3087e+00, -2.0735e+00, -2.6298e+00,\n",
       "         -6.5131e-02, -6.1434e-01, -2.0184e+00,  3.5808e-01, -7.6865e+00],\n",
       "        [ 7.1543e+00,  7.9300e+00,  1.0703e+00,  8.6227e+00,  3.3025e+00,\n",
       "          8.0465e+00,  3.3910e-01,  2.8582e+00, -1.1058e+01, -1.6462e+01],\n",
       "        [ 6.5464e+00, -5.7946e+00,  3.0876e+00,  2.9262e+00, -8.7359e+00,\n",
       "          4.3990e-01,  2.0086e+00,  7.6235e-01,  4.5087e-01,  4.6996e+00],\n",
       "        [ 9.7215e+00, -8.3284e+00, -5.8941e-01,  1.2620e-01, -2.7286e+00,\n",
       "          4.4727e+00,  9.3183e+00, -7.1370e+00, -8.1544e+00,  1.6765e+01],\n",
       "        [ 9.3484e+00,  1.0290e+01,  7.5236e+00, -2.2011e+00, -7.2061e+00,\n",
       "          2.4626e+00,  1.4825e+01, -2.4789e+00, -3.3077e+00, -3.7237e+00],\n",
       "        [ 4.4457e+00,  3.0219e+00,  2.9842e+00, -8.6305e+00, -7.2651e+00,\n",
       "          6.0070e-01,  1.5434e+01, -5.5309e+00, -3.3078e+00,  4.7290e+00],\n",
       "        [ 5.4705e+00,  5.6777e+00,  9.3062e+00, -8.3432e+00, -1.2994e+01,\n",
       "         -3.9027e+00,  1.5950e+01, -5.2074e+00,  3.5812e+00,  3.1695e+00],\n",
       "        [ 7.4471e+00,  6.8604e-01,  4.1298e+00, -4.2895e+00, -6.0068e+00,\n",
       "          9.2732e-01,  1.1975e+01, -5.0020e+00,  3.3042e+00,  1.2442e+01],\n",
       "        [ 3.2118e+00, -1.9823e+00, -1.1668e+00,  1.8920e+01,  7.1807e+00,\n",
       "          8.3227e+00, -2.2057e+01,  1.3963e+01,  7.5224e-01, -2.4143e+01],\n",
       "        [-1.2223e+01,  1.4295e+00, -2.2727e+00,  5.0594e+00, -1.8047e+01,\n",
       "         -1.2014e+00, -1.3860e+01,  1.5097e+01,  2.1383e+01, -1.3769e+01],\n",
       "        [-3.1843e-01,  9.4451e+00, -2.9667e+00,  1.8148e+01, -9.2452e+00,\n",
       "          9.3284e+00, -7.4866e+00,  1.5397e+01, -7.0031e-01, -8.2681e+00],\n",
       "        [ 1.2554e+00, -1.6291e+00,  7.2768e+00, -2.2492e+01, -8.9195e+00,\n",
       "         -9.0858e+00,  2.0462e+01, -1.4287e+01,  3.6989e+00,  1.2567e+01],\n",
       "        [ 1.3114e-01, -2.0814e+00,  1.8317e-01,  1.4374e+00,  2.3021e+01,\n",
       "          3.3689e+00, -1.6179e+01, -1.1413e+00, -4.8217e+00, -2.7916e+01],\n",
       "        [ 3.0663e+00,  1.5051e+01,  6.1590e+00,  2.3576e+01, -2.4421e+01,\n",
       "          7.7423e+00, -7.1338e-01,  2.2096e+01,  2.7699e+00, -5.1520e-01],\n",
       "        [-1.1767e+01,  2.1043e+01, -2.8463e+00,  2.3038e+01, -1.7175e+01,\n",
       "          8.2852e+00, -1.6019e+01,  2.9605e+01,  8.4161e+00, -2.1559e+01],\n",
       "        [ 1.5920e+01, -1.9504e+01,  3.6043e+00,  9.6231e+00,  7.2945e+00,\n",
       "          4.5901e+00, -6.2734e+00, -3.2955e+00, -8.9534e+00,  9.9468e+00],\n",
       "        [ 1.8270e+00,  1.0860e+01, -3.4593e+00,  2.2090e+00,  1.3516e-01,\n",
       "          6.7893e+00,  6.0329e+00,  2.0339e+00, -9.0322e+00, -5.9080e+00],\n",
       "        [ 4.3039e+00,  1.9295e+01, -4.7532e+00,  1.9858e+00, -1.2076e-01,\n",
       "          7.3406e+00,  1.0200e+01,  8.2297e-01, -1.2901e+01, -1.6366e+01],\n",
       "        [ 7.9624e+00,  1.7340e+01,  1.6503e+01,  9.3032e+00, -2.0476e+01,\n",
       "         -5.6713e-01,  7.4093e+00,  1.2080e+01,  2.5774e+00, -2.0068e+01],\n",
       "        [ 1.2706e-01,  1.4066e+00, -6.6718e+00, -1.8050e+00,  7.3297e+00,\n",
       "          7.8601e+00,  2.6934e+00, -2.7734e+00, -9.4738e+00, -2.7246e+00],\n",
       "        [ 1.7865e+01, -1.0730e+01,  7.6242e+00,  9.8235e-02, -4.5955e+00,\n",
       "          1.9135e+00,  1.1994e+01, -7.7325e+00, -2.4718e-03,  2.2351e+01],\n",
       "        [-1.3557e+01,  2.7826e+01, -1.6434e-01,  4.6787e+00, -1.8243e+01,\n",
       "         -2.5923e-01, -1.4951e+00,  1.8047e+01,  6.5197e+00, -2.8731e+01],\n",
       "        [ 1.1869e+01, -5.8806e+00,  7.0753e+00, -1.7584e+01, -7.9726e+00,\n",
       "         -3.4689e+00,  2.7197e+01, -1.8281e+01, -1.7181e+00,  2.9066e+01],\n",
       "        [-2.6798e+00,  4.2741e+00, -4.8776e+00,  1.0969e+01, -7.1665e+00,\n",
       "          6.6552e+00, -7.6975e+00,  1.2446e+01,  2.7363e+00, -7.4744e+00],\n",
       "        [-6.2489e+00,  7.1809e+00,  2.2254e+00, -5.0831e+00, -3.5325e+00,\n",
       "         -1.2120e+00,  4.2965e-01,  1.8832e+00,  4.0715e+00, -1.0282e+01],\n",
       "        [ 4.8664e+01, -2.7347e+01,  2.7651e+01, -2.0172e+01,  2.2599e+01,\n",
       "         -2.9387e+00,  3.7101e+01, -4.3968e+01, -1.8226e+01,  4.1656e+01],\n",
       "        [-2.1740e+01,  2.6485e+01,  2.1249e+00,  2.0870e+00, -2.5595e+01,\n",
       "         -3.9252e+00, -3.1607e+00,  2.1253e+01,  1.4208e+01, -2.1882e+01],\n",
       "        [ 1.6575e+00,  2.5548e+01, -3.7961e+00, -6.1886e+00, -9.7995e+00,\n",
       "          4.2437e+00,  2.3134e+01, -2.6153e+00, -1.3071e+01, -9.5473e+00],\n",
       "        [ 1.9483e+00, -5.0527e+00,  3.0629e+00, -8.1197e+00, -1.0499e+00,\n",
       "         -2.4679e+00,  4.6454e+00, -6.5349e+00, -3.6861e-01,  1.0492e+00],\n",
       "        [ 3.2117e+00,  7.0633e+00,  7.8792e+00, -1.3223e+00, -1.1713e+01,\n",
       "         -2.5156e+00,  7.2799e+00,  2.3232e+00,  8.1297e-01, -7.2490e+00],\n",
       "        [-5.8600e-01,  1.8789e+01,  3.5345e+00,  9.8820e+00, -2.3953e+01,\n",
       "          1.8874e+00,  4.9284e+00,  1.5182e+01,  2.7269e+00, -1.5112e+01],\n",
       "        [ 1.1262e+01,  4.5450e+00,  5.9149e+00,  7.4231e+00, -2.2019e+01,\n",
       "          3.0872e+00,  1.2775e+01,  4.9998e+00,  2.4218e+00,  1.0277e+01],\n",
       "        [ 1.6146e+01, -3.3931e-01,  8.4635e+00,  2.3061e+01,  1.2880e+01,\n",
       "          1.2218e+01, -1.4341e+01,  1.1382e+01, -6.8946e+00, -1.7386e+01],\n",
       "        [-1.3494e+01,  1.1879e+01,  5.6557e+00, -1.2072e+01, -2.9828e+01,\n",
       "         -9.6500e+00,  1.2078e+01,  4.4017e+00,  1.9802e+01,  7.5479e+00],\n",
       "        [ 3.5460e+01, -2.5401e+01,  6.9969e+00, -1.4728e+01,  1.7915e+01,\n",
       "          3.3859e+00,  2.7061e+01, -3.4304e+01, -1.8187e+01,  3.2375e+01],\n",
       "        [ 1.6371e+01, -9.3880e+00,  6.6228e+00,  5.5096e+00,  7.2511e+00,\n",
       "          3.7693e+00, -3.3361e+00, -3.5230e+00, -2.7213e+00, -9.0933e+00],\n",
       "        [ 1.3986e+01, -1.9271e+01,  9.4571e-01, -1.5037e+01,  3.4361e+00,\n",
       "         -9.8127e-02,  1.8590e+01, -2.3762e+01, -2.7411e+00,  3.7795e+01],\n",
       "        [ 9.4925e+00, -9.4717e+00,  1.8846e+00,  1.0314e+01, -1.1632e+01,\n",
       "          4.9917e+00,  2.3610e-01,  4.0155e+00,  1.2021e+00,  1.3447e+01],\n",
       "        [ 8.7059e+00, -1.6349e-01,  8.6939e+00,  1.3902e+01, -9.1455e+00,\n",
       "          4.1069e+00, -3.3521e+00,  9.1631e+00,  3.9339e+00,  3.9731e-01],\n",
       "        [-1.3016e+01,  1.6522e+01, -4.7560e+00,  6.8877e+00, -2.4649e+01,\n",
       "          9.1771e-01, -2.6866e+00,  1.7711e+01,  8.3253e+00, -1.5376e+01],\n",
       "        [ 1.8945e+01, -3.3057e+00,  1.8092e+00,  1.4253e+01,  1.1708e+01,\n",
       "          1.2419e+01,  1.6370e+00, -2.3365e+00, -1.8562e+01,  4.2731e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
