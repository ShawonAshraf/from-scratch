{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "\n",
    "from typing import Any, Tuple\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import lightning.pytorch as L\n",
    "from einops import rearrange\n",
    "\n",
    "torch.manual_seed(2023)\n",
    "np.random.seed(2023)\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = FashionMNIST(root='~/.cache/torchvision_cache', train=True, download=True,\n",
    "#                         transform=transforms.Compose([\n",
    "#                         transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]))\n",
    "\n",
    "\n",
    "trainset = MNIST(download=True, train=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainset[0][0].squeeze(), cmap=\"gray\")\n",
    "print(trainset[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAELoss(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        x_hat: torch.Tensor,\n",
    "        mean: torch.Tensor,\n",
    "        log_var: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        reproduction_loss = F.binary_cross_entropy(\n",
    "            input=x_hat, target=x, reduction=\"sum\"\n",
    "        )\n",
    "        kl_divergence = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "        return reproduction_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(L.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        # latent space\n",
    "        self.latent_mean = nn.Linear(512, 256)\n",
    "        self.latent_log_var = nn.Linear(512, 256)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def reparameterisation(\n",
    "        self, mean: torch.Tensor, log_var: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # assuming log_var\n",
    "        # un-log and then sqrt to get the std-dev\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std).to(self.device)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Any:\n",
    "        out = self.encoder(x)\n",
    "\n",
    "        mean = self.latent_mean(out)\n",
    "        mean = F.leaky_relu(mean, 0.2)\n",
    "\n",
    "        log_var = self.latent_log_var(out)\n",
    "        log_var = F.leaky_relu(log_var, 0.2)\n",
    "\n",
    "        z = self.reparameterisation(mean, log_var)\n",
    "\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        return x_hat, mean, log_var\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return optim.AdamW(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        x, _ = batch\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x_hat, mean, log_var = self(x)\n",
    "\n",
    "        loss = F.binary_cross_entropy(x_hat, x, reduction=\"sum\")\n",
    "        kl = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "        loss += kl\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return {\"loss\": loss, \"log\": {\"Loss/Training\": loss}}\n",
    "\n",
    "\n",
    "# model = VAE()\n",
    "# x = torch.randn(8, 784)\n",
    "# y = torch.zeros(8, )\n",
    "\n",
    "# x_hat, mean, log_var = model(x)\n",
    "# print(x_hat)\n",
    "\n",
    "# loss = F.binary_cross_entropy(x_hat, x, reduction=\"sum\")\n",
    "# kl = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "# print(loss + kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train() -> Any:\n",
    "    logger = L.loggers.TensorBoardLogger(\n",
    "        \"tb_logs\", name=\"vae_fashion_mnist\", log_graph=True\n",
    "    )\n",
    "\n",
    "    model = VAE()\n",
    "    trainer = L.Trainer(max_epochs=5, devices=1, accelerator=\"gpu\", logger=logger)\n",
    "    # trainer = L.Trainer(max_epochs=5, devices=1, accelerator=\"cpu\", logger=logger)\n",
    "    trainer.fit(model, trainloader)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir tb_logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(\n",
    "        256,\n",
    "    ).to(model.device)\n",
    "    out = model.decoder(x)\n",
    "\n",
    "    out = torch.unflatten(out, -1, (28, 28))\n",
    "    print(out.size())\n",
    "\n",
    "    plt.imshow(out, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image = torch.flatten(trainset[0][0])\n",
    "    print(trainset[0][1])\n",
    "    out, _, _ = model(image)\n",
    "\n",
    "    out = torch.unflatten(out, -1, (28, 28))\n",
    "\n",
    "plt.imshow(out, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(image: torch.Tensor) -> torch.Tensor:\n",
    "    flattened_image = torch.flatten(image)\n",
    "    out, _, _ = model(flattened_image)\n",
    "    out = torch.unflatten(out, -1, (28, 28))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(trainset[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_pick_n(n: int = 8, max=len(trainset)) -> Tuple:\n",
    "    indexes = torch.randint(0, max, size=(n,)).tolist()\n",
    "    selection = [trainset[i][0] for i in indexes]\n",
    "    actuals = [torch.from_numpy(np.array(im, dtype=np.float32)) for im in selection]\n",
    "    generated = [inference(im) for im in selection]\n",
    "\n",
    "    stacked_generated = torch.stack(generated)\n",
    "    stacked_actuals = torch.stack(actuals)\n",
    "\n",
    "    # drop the extra dim in actuals\n",
    "    stacked_actuals = rearrange(stacked_actuals, \"b 1 h w -> b h w\")\n",
    "\n",
    "    return stacked_generated, stacked_actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated, actuals = randomly_pick_n()\n",
    "print(generated.size())\n",
    "print(actuals.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plot(generated: list, actuals: list) -> None:\n",
    "    fig = plt.figure(1, figsize=[12, 6])\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for idx, gen in enumerate(generated):\n",
    "        ax = fig.add_subplot(1, len(generated), idx + 1)\n",
    "        ax.set_title(f\"generated_{idx}\")\n",
    "        plt.imshow(gen)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    for idx, act in enumerate(actuals):\n",
    "        ax = fig.add_subplot(2, len(actuals), idx + 1)\n",
    "        ax.set_title(f\"actual_{idx}\")\n",
    "        plt.imshow(act)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"Actual (upper) vs Generated(lower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(generated.tolist(), actuals.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
