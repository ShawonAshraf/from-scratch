{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "torch.manual_seed(2023)\n",
    "np.random.seed(2023)\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Tuple\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "train_dataset = MNIST(download=True, train=True)\n",
    "val_dataset = MNIST(train=False)\n",
    "\n",
    "\n",
    "def collate(batch: Any) -> torch.Tensor:\n",
    "    images = list(zip(*batch))[0]\n",
    "    image_arrays = np.array([np.array(im).flatten() for im in images], dtype=np.float32)\n",
    "\n",
    "    return torch.from_numpy(image_arrays / 255.0)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, shuffle=True, batch_size=256, collate_fn=collate\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=256, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import lightning.pytorch as L\n",
    "\n",
    "import torchvision as tv\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class AutoEncoder(L.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(784, 512)\n",
    "        self.latent_space = nn.Linear(512, 256)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 512), nn.Linear(512, 784), nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.encoder(x)\n",
    "        out = F.leaky_relu(out)\n",
    "        out = self.latent_space(out)\n",
    "        out = F.leaky_relu(out)\n",
    "        out = self.decoder(out)\n",
    "        out = F.leaky_relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        return optim.AdamW(params=self.parameters(), lr=0.0005)\n",
    "\n",
    "    def __compute_loss(self, batch: torch.Tensor) -> torch.Tensor:\n",
    "        out = self(batch)\n",
    "        loss = self.criterion(out, batch)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_idx: int) -> STEP_OUTPUT:\n",
    "        loss = self.__compute_loss(batch)\n",
    "        self.log(\"training_loss\", loss)\n",
    "\n",
    "        return {\"loss\": loss, \"log\": {\"training_loss\": loss}}\n",
    "\n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> STEP_OUTPUT:\n",
    "        loss = self.__compute_loss(batch)\n",
    "        self.log(\"validation_loss\", loss)\n",
    "\n",
    "        # log images\n",
    "        generated = self(batch)\n",
    "        # reshape to original size\n",
    "        generated = torch.unflatten(generated, dim=-1, sizes=(28, 28))\n",
    "        actuals = torch.unflatten(batch, dim=-1, sizes=(28, 28))\n",
    "\n",
    "        # create grids\n",
    "        gen_grid = tv.utils.make_grid(\n",
    "            rearrange(generated, \"batch h w -> batch 1 h w\"), nrow=8\n",
    "        )\n",
    "        actual_grid = tv.utils.make_grid(\n",
    "            rearrange(actuals, \"batch h w -> batch 1 h w\"), nrow=8\n",
    "        )\n",
    "\n",
    "        # add to tensorboard\n",
    "        self.logger.experiment.add_image(\n",
    "            \"generated_images\", gen_grid, self.current_epoch\n",
    "        )\n",
    "        self.logger.experiment.add_image(\n",
    "            \"actual_images\", actual_grid, self.current_epoch\n",
    "        )\n",
    "\n",
    "        return {\"loss\": loss, \"log\": {\"validation_loss\": loss}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=5):\n",
    "    logger = L.loggers.TensorBoardLogger(\n",
    "        \"tb_logs\",  # type: ignore\n",
    "        name=\"autoencoder_mnist\",\n",
    "        log_graph=True,\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"gpu\", devices=1, max_epochs=epochs, benchmark=True, logger=logger\n",
    "    )\n",
    "\n",
    "    model = AutoEncoder()\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(image: Any, model=model) -> torch.Tensor:\n",
    "    inputs = torch.from_numpy(np.array(image, dtype=np.float32) / 255.0)\n",
    "    gen = model(torch.flatten(inputs))\n",
    "\n",
    "    gen = torch.unflatten(gen, dim=-1, sizes=(28, 28))\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "sample = val_dataset[3]\n",
    "gen = inference(sample[0])\n",
    "plt.imshow(gen.cpu().numpy())\n",
    "print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_pick_n(n: int = 8, max=len(val_dataset)) -> Tuple:\n",
    "    indexes = torch.randint(0, max, size=(n,)).tolist()\n",
    "    selection = [val_dataset[i][0] for i in indexes]\n",
    "    actuals = [torch.from_numpy(np.array(im, dtype=np.float32)) for im in selection]\n",
    "    generated = [inference(im) for im in selection]\n",
    "\n",
    "    return torch.stack(generated), torch.stack(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated, actuals = randomly_pick_n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plot(generated: list, actuals: list) -> None:\n",
    "    fig = plt.figure(1, figsize=[12, 6])\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for idx, gen in enumerate(generated):\n",
    "        ax = fig.add_subplot(1, len(generated), idx + 1)\n",
    "        ax.set_title(f\"generated_{idx}\")\n",
    "        plt.imshow(gen)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    for idx, act in enumerate(actuals):\n",
    "        ax = fig.add_subplot(2, len(actuals), idx + 1)\n",
    "        ax.set_title(f\"actual_{idx}\")\n",
    "        plt.imshow(act)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"Actual (upper) vs Generated(lower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(generated.tolist(), actuals.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
